{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n1- Read data into a dataframe (mma)\\n2- Separate data into train/test (80/20) (mma_train , mma_test)\\n3- Calculate frequency in train data | test data of each product over all orders (mma_train_freq | mma_test_freq)\\n4- Create a solution table with columns (ProductID|SubstituteID|PFrequency|DepartmentID|AisleID|Selected?) (solution_df)\\n5- Populate the solution table ProductID column with a {SELECT DISTINCT ProductID} over original data\\n6- Add information of product frequency on orders per ProductID to solution table (PFrequency), by joining with mma_train_freq\\n7- Add DepartmentID|AisleID to solution table by joining with main table\\n8- Create SubstituteIDs for each ProductID\\n    >> For each AisleID|DepartmentID group:\\n        1)Select all ProductIDs | ProductNames under Aisle|Department\\n        2)Do a similarity analysis, and try to cluster similar product names\\n        3)On each cluster, compare frequency of product in orders, and select the most frequent product as SubstituteID\\n            Left Join with frequency table, and compare\\n        4)For outliers (products that are not similar to any other product), copy ProductID as SubstituteID\\n        5)Append ProductIDs|SubstituteIDs to Substitute table\\n9- Add SubstituteIDs to solution table by joining with Substitute table\\n10- Prepare objective function as a method\\n11- Prepare constraints as a method\\n12- Configure optimization with Objective, Constraints and Solution Table\\n13- Run optimization\\n14- Export solution table as csv\\n15- Test solution table with test data\\n16- Calculate score against metrics\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "1- Read data into a dataframe (mma)\n",
    "2- Separate data into train/test (80/20) (mma_train , mma_test)\n",
    "3- Calculate frequency in train data | test data of each product over all orders (mma_train_freq | mma_test_freq)\n",
    "4- Create a solution table with columns (ProductID|SubstituteID|PFrequency|DepartmentID|AisleID|Selected?) (solution_df)\n",
    "5- Populate the solution table ProductID column with a {SELECT DISTINCT ProductID} over original data\n",
    "6- Add information of product frequency on orders per ProductID to solution table (PFrequency), by joining with mma_train_freq\n",
    "7- Add DepartmentID|AisleID to solution table by joining with main table\n",
    "8- Create SubstituteIDs for each ProductID\n",
    "    >> For each AisleID|DepartmentID group:\n",
    "        1)Select all ProductIDs | ProductNames under Aisle|Department\n",
    "        2)Do a similarity analysis, and try to cluster similar product names\n",
    "        3)On each cluster, compare frequency of product in orders, and select the most frequent product as SubstituteID\n",
    "            Left Join with frequency table, and compare\n",
    "        4)For outliers (products that are not similar to any other product), copy ProductID as SubstituteID\n",
    "        5)Append ProductIDs|SubstituteIDs to Substitute table\n",
    "9- Add SubstituteIDs to solution table by joining with Substitute table\n",
    "10- Prepare objective function as a method\n",
    "11- Prepare constraints as a method\n",
    "12- Configure optimization with Objective, Constraints and Solution Table\n",
    "13- Run optimization\n",
    "14- Export solution table as csv\n",
    "15- Test solution table with test data\n",
    "16- Calculate score against metrics\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import sklearn as sk\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import time\n",
    "import pulp\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Read data into a dataframe (mma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>aisle</th>\n",
       "      <th>department_id</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>Bulgarian Yogurt</td>\n",
       "      <td>120</td>\n",
       "      <td>yogurt</td>\n",
       "      <td>16</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "      <td>Organic 4% Milk Fat Whole Milk Cottage Cheese</td>\n",
       "      <td>108</td>\n",
       "      <td>other creams cheeses</td>\n",
       "      <td>16</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>Organic Celery Hearts</td>\n",
       "      <td>83</td>\n",
       "      <td>fresh vegetables</td>\n",
       "      <td>4</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "      <td>Cucumber Kirby</td>\n",
       "      <td>83</td>\n",
       "      <td>fresh vegetables</td>\n",
       "      <td>4</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>Lightly Smoked Sardines in Olive Oil</td>\n",
       "      <td>95</td>\n",
       "      <td>canned meat seafood</td>\n",
       "      <td>15</td>\n",
       "      <td>canned goods</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id                                   product_name  \\\n",
       "0         1       49302                               Bulgarian Yogurt   \n",
       "1         1       11109  Organic 4% Milk Fat Whole Milk Cottage Cheese   \n",
       "2         1       10246                          Organic Celery Hearts   \n",
       "3         1       49683                                 Cucumber Kirby   \n",
       "4         1       43633           Lightly Smoked Sardines in Olive Oil   \n",
       "\n",
       "   aisle_id                 aisle  department_id    department  \n",
       "0       120                yogurt             16    dairy eggs  \n",
       "1       108  other creams cheeses             16    dairy eggs  \n",
       "2        83      fresh vegetables              4       produce  \n",
       "3        83      fresh vegetables              4       produce  \n",
       "4        95   canned meat seafood             15  canned goods  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reasd the data\n",
    "mma = pd.read_csv('data/mma_mart.csv')\n",
    "mma.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id         97833\n",
       "product_id       35070\n",
       "product_name     35070\n",
       "aisle_id           134\n",
       "aisle              134\n",
       "department_id       21\n",
       "department          21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check lenght of order_ids\n",
    "mma.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Separate data into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mma_train = mma[mma['order_id'] <= 80000]\n",
    "mma_test  = mma[mma['order_id'] > 80000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Calculate frequency in train data | test data of each product over all orders (mma-train-freq | mma-test-freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count frequency of products in train and test data\n",
    "f_counts_train = mma_train['product_id'].value_counts()\n",
    "f_counts_test = mma_test['product_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes for frequency counts\n",
    "\n",
    "## Train   \n",
    "f_counts_train_df = f_counts_train.to_frame().reset_index()\n",
    "f_counts_train_df.columns = ['product_id', 'frequency']\n",
    "## Test\n",
    "f_counts_test_df = f_counts_test.to_frame().reset_index()\n",
    "f_counts_test_df.columns = ['product_id', 'frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mma_train_freq = f_counts_train_df.sort_values(by=['frequency'], ascending=False)\n",
    "mma_test_freq = f_counts_test_df.sort_values(by=['frequency'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Create a solution table with columns (ProductID|SubstituteID|PFrequency|DepartmentID|AisleID|Selected?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_df = pd.DataFrame(columns=['ProductID', 'SubstituteID', 'PFrequency', 'DepartmentID', 'AisleID', 'Selected?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5- Populate the solution table ProductID column with a {SELECT DISTINCT ProductID} over original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>SubstituteID</th>\n",
       "      <th>PFrequency</th>\n",
       "      <th>DepartmentID</th>\n",
       "      <th>AisleID</th>\n",
       "      <th>Selected?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4788</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17643</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8823</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18351</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31588</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ProductID SubstituteID PFrequency DepartmentID AisleID Selected?\n",
       "4788           1          NaN        NaN          NaN     NaN       NaN\n",
       "17643          2          NaN        NaN          NaN     NaN       NaN\n",
       "8823           3          NaN        NaN          NaN     NaN       NaN\n",
       "18351          4          NaN        NaN          NaN     NaN       NaN\n",
       "31588          8          NaN        NaN          NaN     NaN       NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_df['ProductID'] = mma['product_id'].unique()\n",
    "solution_df.sort_values(by=['ProductID'], inplace=True)\n",
    "solution_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6- Add information of product frequency on orders per ProductID to solution table (PFrequency), by joining with mma_train_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>SubstituteID</th>\n",
       "      <th>DepartmentID</th>\n",
       "      <th>AisleID</th>\n",
       "      <th>Selected?</th>\n",
       "      <th>PFrequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID SubstituteID DepartmentID AisleID Selected?  PFrequency\n",
       "0          1          NaN          NaN     NaN       NaN        51.0\n",
       "1          2          NaN          NaN     NaN       NaN         2.0\n",
       "2          3          NaN          NaN     NaN       NaN         4.0\n",
       "3          4          NaN          NaN     NaN       NaN         6.0\n",
       "4          8          NaN          NaN     NaN       NaN         1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_df = pd.merge(solution_df, mma_train_freq, how='left', left_on=['ProductID'], right_on=('product_id'))\n",
    "solution_df.drop(columns=['product_id'], inplace=True)\n",
    "solution_df.drop(columns=['PFrequency'], inplace=True)\n",
    "solution_df.rename(columns={'frequency':'PFrequency'}, inplace=True)\n",
    "solution_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7- Add DepartmentID|AisleID to solution table by joining with main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id         17575\n",
       "product_id       33171\n",
       "product_name     33171\n",
       "aisle_id           134\n",
       "aisle              134\n",
       "department_id       21\n",
       "department          21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mma_train_unique = mma_train.drop_duplicates(subset=['product_id', 'department_id', 'aisle_id'])\n",
    "mma_train_unique.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>19</th>\n",
       "      <th>61</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>13</th>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>7</th>\n",
       "      <th>94</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>38</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>1</th>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49681</th>\n",
       "      <th>1</th>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49683</th>\n",
       "      <th>4</th>\n",
       "      <th>83</th>\n",
       "      <td>2354</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49685</th>\n",
       "      <th>1</th>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49686</th>\n",
       "      <th>3</th>\n",
       "      <th>112</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49688</th>\n",
       "      <th>11</th>\n",
       "      <th>73</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33171 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   order_id  product_name  aisle  department\n",
       "product_id department_id aisle_id                                           \n",
       "1          19            61              51             1      1           1\n",
       "2          13            104              2             1      1           1\n",
       "3          7             94               4             1      1           1\n",
       "4          1             38               6             1      1           1\n",
       "8          1             116              1             1      1           1\n",
       "...                                     ...           ...    ...         ...\n",
       "49681      1             38               1             1      1           1\n",
       "49683      4             83            2354             1      1           1\n",
       "49685      1             42               2             1      1           1\n",
       "49686      3             112              4             1      1           1\n",
       "49688      11            73               3             1      1           1\n",
       "\n",
       "[33171 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if product_id|department_id|aisle_id is unique\n",
    "mma_train.groupby(['product_id', 'department_id', 'aisle_id']).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>SubstituteID</th>\n",
       "      <th>DepartmentID</th>\n",
       "      <th>AisleID</th>\n",
       "      <th>Selected?</th>\n",
       "      <th>PFrequency</th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>aisle</th>\n",
       "      <th>department_id</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>61.0</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>19.0</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12209.0</td>\n",
       "      <td>All-Seasons Salt</td>\n",
       "      <td>104.0</td>\n",
       "      <td>spices seasonings</td>\n",
       "      <td>13.0</td>\n",
       "      <td>pantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2998.0</td>\n",
       "      <td>Robust Golden Unsweetened Oolong Tea</td>\n",
       "      <td>94.0</td>\n",
       "      <td>tea</td>\n",
       "      <td>7.0</td>\n",
       "      <td>beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13379.0</td>\n",
       "      <td>Smart Ones Classic Favorites Mini Rigatoni Wit...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>frozen meals</td>\n",
       "      <td>1.0</td>\n",
       "      <td>frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66768.0</td>\n",
       "      <td>Cut Russet Potatoes Steam N' Mash</td>\n",
       "      <td>116.0</td>\n",
       "      <td>frozen produce</td>\n",
       "      <td>1.0</td>\n",
       "      <td>frozen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID SubstituteID DepartmentID AisleID Selected?  PFrequency  \\\n",
       "0          1          NaN          NaN     NaN       NaN        51.0   \n",
       "1          2          NaN          NaN     NaN       NaN         2.0   \n",
       "2          3          NaN          NaN     NaN       NaN         4.0   \n",
       "3          4          NaN          NaN     NaN       NaN         6.0   \n",
       "4          8          NaN          NaN     NaN       NaN         1.0   \n",
       "\n",
       "   order_id                                       product_name  aisle_id  \\\n",
       "0    1107.0                         Chocolate Sandwich Cookies      61.0   \n",
       "1   12209.0                                   All-Seasons Salt     104.0   \n",
       "2    2998.0               Robust Golden Unsweetened Oolong Tea      94.0   \n",
       "3   13379.0  Smart Ones Classic Favorites Mini Rigatoni Wit...      38.0   \n",
       "4   66768.0                  Cut Russet Potatoes Steam N' Mash     116.0   \n",
       "\n",
       "               aisle  department_id department  \n",
       "0      cookies cakes           19.0     snacks  \n",
       "1  spices seasonings           13.0     pantry  \n",
       "2                tea            7.0  beverages  \n",
       "3       frozen meals            1.0     frozen  \n",
       "4     frozen produce            1.0     frozen  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution_df = pd.merge(solution_df, mma_train_unique, how='left', left_on=['ProductID'], right_on=('product_id'))\n",
    "solution_df.drop(columns=['product_id'], inplace=True)\n",
    "solution_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductID</th>\n",
       "      <th>SubstituteID</th>\n",
       "      <th>Selected?</th>\n",
       "      <th>PFrequency</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>61.0</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>All-Seasons Salt</td>\n",
       "      <td>104.0</td>\n",
       "      <td>pantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Robust Golden Unsweetened Oolong Tea</td>\n",
       "      <td>94.0</td>\n",
       "      <td>beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Smart Ones Classic Favorites Mini Rigatoni Wit...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cut Russet Potatoes Steam N' Mash</td>\n",
       "      <td>116.0</td>\n",
       "      <td>frozen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ProductID SubstituteID Selected?  PFrequency  \\\n",
       "0          1          NaN       NaN        51.0   \n",
       "1          2          NaN       NaN         2.0   \n",
       "2          3          NaN       NaN         4.0   \n",
       "3          4          NaN       NaN         6.0   \n",
       "4          8          NaN       NaN         1.0   \n",
       "\n",
       "                                        product_name  aisle_id department  \n",
       "0                         Chocolate Sandwich Cookies      61.0     snacks  \n",
       "1                                   All-Seasons Salt     104.0     pantry  \n",
       "2               Robust Golden Unsweetened Oolong Tea      94.0  beverages  \n",
       "3  Smart Ones Classic Favorites Mini Rigatoni Wit...      38.0     frozen  \n",
       "4                  Cut Russet Potatoes Steam N' Mash     116.0     frozen  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Given aisle_id and department_id are 1-1 | N-1, we can drop department_id and keep aisle_id as the lowest granularity\n",
    "solution_df.drop(columns=['order_id', 'aisle','DepartmentID', 'AisleID', 'department_id'], inplace=True)\n",
    "solution_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8- Create SubstituteIDs for each ProductID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source : https://medium.com/towards-data-science/clustering-product-names-with-python-part-1-f9418f8705c8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "\n",
    "#Libraries for preprocessing\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import webcolors\n",
    "\n",
    "#Download once if using NLTK for preprocessing\n",
    "import nltk\n",
    "\n",
    "#Libraries for vectorisation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "#Libraries for clustering\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### METHODS ####\n",
    "\n",
    "#Stem and make lower case\n",
    "def stemSentence(sentence):\n",
    "    porter = PorterStemmer()\n",
    "    token_words = word_tokenize(sentence)\n",
    "    stem_sentence = [porter.stem(word) for word in token_words]\n",
    "    return ' '.join(stem_sentence)\n",
    "\n",
    "#Plot topics function. Code from: https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html\n",
    "def plot_top_words(model, feature_names, n_top_words, title):\n",
    "    fig, axes = plt.subplots(6, 5, figsize=(30, 30), sharex=True)\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[:-n_top_words - 1:-1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7)\n",
    "        ax.set_title(f'Topic {topic_idx +1}',\n",
    "                     fontdict={'fontsize': 30})\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "        for i in 'top right left'.split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all products under aisle\n",
    "aisle_products = solution_df[solution_df['aisle_id'] == 1]\n",
    "# Select all product names under aisle\n",
    "aisle_products_names_1 = aisle_products['product_name']\n",
    "# Remove stopwords, punctuation, and numbers\n",
    "aisle_products_names_2 = [remove_stopwords(x)\\\n",
    "    .translate(str.maketrans('','',string.punctuation))\\\n",
    "    .translate(str.maketrans('','',string.digits))\\\n",
    "    for x in aisle_products_names_1]\n",
    "\n",
    "# Stemming and making words lower case\n",
    "aisle_products_names_3 = pd.Series([stemSentence(x) for x in aisle_products_names_2])\n",
    "# Removing Color Names\n",
    "colors = list(webcolors.CSS3_NAMES_TO_HEX)\n",
    "colors = [stemSentence(x) for x in colors if x not in ('bisque','blanchedalmond','chocolate','honeydew','lime',\n",
    "                                     'olive','orange','plum','salmon','tomato','wheat')]\n",
    "aisle_product_names_4 = [' '.join([x for x in string.split() if x not in colors]) for string in aisle_products_names_3]\n",
    "\n",
    "# Vectorizing\n",
    "## Bag of Words\n",
    "vectorizer_cv = CountVectorizer(analyzer='word')\n",
    "X_cv = vectorizer_cv.fit_transform(aisle_product_names_4)\n",
    "## TF-IDF\n",
    "vectorizer_wtf = TfidfVectorizer(analyzer='word')\n",
    "X_wtf = vectorizer_wtf.fit_transform(aisle_product_names_4)\n",
    "## LDA\n",
    "lda = LatentDirichletAllocation(n_components=30, learning_decay=0.9)\n",
    "X_lda = lda.fit(X_cv)\n",
    "## FuzzyWuzzy\n",
    "X_fuzz = pd.crosstab([aisle_product_names_4,aisle_product_names_4],aisle_product_names_4).apply(lambda col: [fuzz.token_sort_ratio(col.name, x) \n",
    "                                                                   for x in col.index.get_level_values(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Show topics\n",
    "# n_top_words = 5\n",
    "# feature_names = vectorizer_cv.get_feature_names_out()\n",
    "# plot_top_words(X_lda, feature_names, n_top_words, '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Test increments of 100 clusters using elbow method\n",
    "# sse={}\n",
    "# for k in np.arange(1,110,1):\n",
    "#     kmeans = KMeans(n_clusters=k, max_iter=1000).fit(X_cv)\n",
    "#     sse[k] = kmeans.inertia_\n",
    "# plt.plot(list(sse.keys()),list(sse.values()))\n",
    "# plt.xlabel('Values for K')\n",
    "# plt.ylabel('SSE')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>add</th>\n",
       "      <th>albacor</th>\n",
       "      <th>almond</th>\n",
       "      <th>american</th>\n",
       "      <th>asian</th>\n",
       "      <th>bacon</th>\n",
       "      <th>bag</th>\n",
       "      <th>bake</th>\n",
       "      <th>bar</th>\n",
       "      <th>barley</th>\n",
       "      <th>...</th>\n",
       "      <th>vegan</th>\n",
       "      <th>veget</th>\n",
       "      <th>vinaigrett</th>\n",
       "      <th>whitefish</th>\n",
       "      <th>whole</th>\n",
       "      <th>wild</th>\n",
       "      <th>winter</th>\n",
       "      <th>with</th>\n",
       "      <th>wrap</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     add  albacor  almond  american  asian  bacon  bag  bake  bar  barley  \\\n",
       "0      0        0       0         0      0      0    0     0    0       0   \n",
       "1      0        0       0         0      0      0    0     0    0       0   \n",
       "2      0        0       0         0      0      0    0     0    0       0   \n",
       "3      0        0       0         0      0      0    0     0    0       0   \n",
       "4      0        0       0         0      0      0    0     0    0       0   \n",
       "..   ...      ...     ...       ...    ...    ...  ...   ...  ...     ...   \n",
       "109    0        0       0         0      0      0    0     0    0       0   \n",
       "110    0        0       0         0      0      0    0     0    0       0   \n",
       "111    0        0       0         0      0      0    0     0    0       0   \n",
       "112    0        0       0         0      0      0    0     0    0       0   \n",
       "113    0        0       0         0      0      0    0     1    0       0   \n",
       "\n",
       "     ...  vegan  veget  vinaigrett  whitefish  whole  wild  winter  with  \\\n",
       "0    ...      0      0           0          0      0     0       0     0   \n",
       "1    ...      0      0           0          0      0     0       0     0   \n",
       "2    ...      0      0           1          0      1     0       0     0   \n",
       "3    ...      0      0           0          0      0     0       0     0   \n",
       "4    ...      0      0           0          0      0     0       0     0   \n",
       "..   ...    ...    ...         ...        ...    ...   ...     ...   ...   \n",
       "109  ...      0      0           0          0      0     0       0     0   \n",
       "110  ...      0      0           0          0      0     0       0     0   \n",
       "111  ...      0      0           0          0      0     0       0     0   \n",
       "112  ...      0      1           0          0      0     0       0     0   \n",
       "113  ...      0      0           0          0      0     0       0     0   \n",
       "\n",
       "     wrap  zucchini  \n",
       "0       0         0  \n",
       "1       0         0  \n",
       "2       0         0  \n",
       "3       0         0  \n",
       "4       0         0  \n",
       "..    ...       ...  \n",
       "109     0         0  \n",
       "110     0         0  \n",
       "111     0         0  \n",
       "112     0         0  \n",
       "113     0         0  \n",
       "\n",
       "[114 rows x 148 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_cv.toarray(),columns=vectorizer_cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (114) does not match length of index (228)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/vilourenco/Documents/GitHub/mma-datathon-2023/solution.ipynb Cell 29\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vilourenco/Documents/GitHub/mma-datathon-2023/solution.ipynb#Y101sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m kmeans\u001b[39m.\u001b[39mfit(X_cv)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vilourenco/Documents/GitHub/mma-datathon-2023/solution.ipynb#Y101sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m result \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([aisle_products_names_1,pd\u001b[39m.\u001b[39mDataFrame(X_cv\u001b[39m.\u001b[39mtoarray(),columns\u001b[39m=\u001b[39mvectorizer_cv\u001b[39m.\u001b[39mget_feature_names_out())],axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vilourenco/Documents/GitHub/mma-datathon-2023/solution.ipynb#Y101sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m result[\u001b[39m'\u001b[39;49m\u001b[39mcluster\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mpredict(X_cv)\n",
      "File \u001b[0;32m~/anaconda3/envs/mma/lib/python3.8/site-packages/pandas/core/frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3947\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3948\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3950\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m~/anaconda3/envs/mma/lib/python3.8/site-packages/pandas/core/frame.py:4143\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4134\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4135\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4136\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4141\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4142\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4143\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   4145\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4146\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   4147\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   4148\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4149\u001b[0m     ):\n\u001b[1;32m   4150\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4151\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/anaconda3/envs/mma/lib/python3.8/site-packages/pandas/core/frame.py:4870\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4867\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4869\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4870\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4871\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mma/lib/python3.8/site-packages/pandas/core/common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (114) does not match length of index (228)"
     ]
    }
   ],
   "source": [
    "#Create 20 clusters\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "kmeans.fit(X_cv)\n",
    "result = pd.concat([aisle_products_names_1, pd.DataFrame(X_cv.toarray(),columns=vectorizer_cv.get_feature_names_out())])\n",
    "result['cluster'] = kmeans.predict(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.0\n",
      "104.0\n",
      "94.0\n",
      "38.0\n",
      "116.0\n",
      "120.0\n",
      "115.0\n",
      "119.0\n",
      "74.0\n",
      "56.0\n",
      "103.0\n",
      "79.0\n",
      "63.0\n",
      "49.0\n",
      "3.0\n",
      "41.0\n",
      "127.0\n",
      "121.0\n",
      "81.0\n",
      "107.0\n",
      "131.0\n",
      "106.0\n",
      "69.0\n",
      "nan\n",
      "78.0\n",
      "47.0\n",
      "123.0\n",
      "83.0\n",
      "58.0\n",
      "66.0\n",
      "87.0\n",
      "14.0\n",
      "105.0\n",
      "134.0\n",
      "98.0\n",
      "22.0\n",
      "23.0\n",
      "111.0\n",
      "50.0\n",
      "9.0\n",
      "96.0\n",
      "92.0\n",
      "89.0\n",
      "88.0\n",
      "130.0\n",
      "77.0\n",
      "65.0\n",
      "95.0\n",
      "128.0\n",
      "7.0\n",
      "6.0\n",
      "97.0\n",
      "2.0\n",
      "112.0\n",
      "51.0\n",
      "75.0\n",
      "70.0\n",
      "93.0\n",
      "34.0\n",
      "21.0\n",
      "29.0\n",
      "19.0\n",
      "45.0\n",
      "4.0\n",
      "108.0\n",
      "37.0\n",
      "91.0\n",
      "24.0\n",
      "129.0\n",
      "46.0\n",
      "16.0\n",
      "52.0\n",
      "12.0\n",
      "17.0\n",
      "59.0\n",
      "67.0\n",
      "122.0\n",
      "1.0\n",
      "8.0\n",
      "82.0\n",
      "31.0\n",
      "109.0\n",
      "124.0\n",
      "40.0\n",
      "117.0\n",
      "72.0\n",
      "110.0\n",
      "85.0\n",
      "73.0\n",
      "44.0\n",
      "100.0\n",
      "42.0\n",
      "84.0\n",
      "30.0\n",
      "25.0\n",
      "27.0\n",
      "11.0\n",
      "90.0\n",
      "20.0\n",
      "5.0\n",
      "13.0\n",
      "133.0\n",
      "48.0\n",
      "53.0\n",
      "114.0\n",
      "68.0\n",
      "43.0\n",
      "125.0\n",
      "57.0\n",
      "55.0\n",
      "28.0\n",
      "10.0\n",
      "101.0\n",
      "36.0\n",
      "54.0\n",
      "26.0\n",
      "64.0\n",
      "126.0\n",
      "80.0\n",
      "15.0\n",
      "60.0\n",
      "18.0\n",
      "132.0\n",
      "62.0\n",
      "99.0\n",
      "33.0\n",
      "102.0\n",
      "86.0\n",
      "39.0\n",
      "113.0\n",
      "35.0\n",
      "76.0\n",
      "118.0\n",
      "71.0\n",
      "32.0\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "For each AisleID|DepartmentID group:\n",
    "    1)Select all ProductIDs | ProductNames under Aisle|Department\n",
    "    2)Do a similarity analysis, and try to cluster similar product names\n",
    "    3)On each cluster, compare frequency of product in orders, and select the most frequent product as SubstituteID\n",
    "        Left Join with frequency table, and compare\n",
    "    4)For outliers (products that are not similar to any other product), copy ProductID as SubstituteID\n",
    "    5)Append ProductIDs|SubstituteIDs to Substitute table\n",
    "\"\"\"\n",
    "\n",
    "for aisle in solution_df.drop_duplicates(['aisle_id'])['aisle_id']:\n",
    "    # Select all products under aisle\n",
    "    aisle_products = solution_df[solution_df['aisle_id'] == aisle]\n",
    "    # Select all product names under aisle\n",
    "    aisle_products_names_1 = aisle_products['product_name']\n",
    "\n",
    "    # Remove stopwords, punctuation, and numbers\n",
    "    aisle_products_names_2 = [remove_stopwords(x)\\\n",
    "        .translate(str.maketrans('','',string.punctuation))\\\n",
    "        .translate(str.maketrans('','',string.digits))\\\n",
    "        for x in aisle_products_names_1]\n",
    "    \n",
    "    # Stemming and making words lower case\n",
    "    aisle_products_names_3 = pd.Series([stemSentence(x) for x in aisle_products_names_2])\n",
    "\n",
    "    # Removing Color Names\n",
    "    colors = list(webcolors.CSS3_NAMES_TO_HEX)\n",
    "    colors = [stemSentence(x) for x in colors if x not in ('bisque','blanchedalmond','chocolate','honeydew','lime',\n",
    "                                         'olive','orange','plum','salmon','tomato','wheat')]\n",
    "    aisle_product_names_4 = [' '.join([x for x in string.split() if x not in colors]) for string in aisle_products_names_3]\n",
    "\n",
    "    # Vectorizing\n",
    "    ## Bag of Words\n",
    "    vectorizer_cv = CountVectorizer(analyzer='word')\n",
    "    X_cv = vectorizer_cv.fit_transform(aisle_product_names_4)\n",
    "\n",
    "    ## TF-IDF\n",
    "    vectorizer_wtf = TfidfVectorizer(analyzer='word')\n",
    "    X_wtf = vectorizer_wtf.fit_transform(aisle_product_names_4)\n",
    "\n",
    "    ## LDA\n",
    "    lda = LatentDirichletAllocation(n_components=30, learning_decay=0.9)\n",
    "    X_lda = lda.fit(X_cv)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
